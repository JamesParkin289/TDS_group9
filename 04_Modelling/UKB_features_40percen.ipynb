{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UKB feature set with missing threshold at 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 year time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1142,1143,1145,1149,1150,1151,1230,1231,1232,1233,2928,2929,2939,2940,2944,2945,2946,2947,2948,2949,2950,2957,2958,2959,2960,2961,2962,2971,2972,2973,2974,2986,2987,2988,2989,2990,2991,2992,3014,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3195,3196,3199,3200,3201,3202,3203,3204,3205,3206,3207,3210,3212,3213) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Initial test_train_split 0.25 and info about test_set:\n",
      "Number and prop(%) of cases   :  3838 , % = 0.323\n",
      "Number and prop(%) of controls:  8030 , % = 0.677\n",
      "Performing SMOTE on test_set:\n",
      "Number and prop(%) of cases   :  6825 , % = 0.459\n",
      "Number and prop(%) of controls:  8030 , % = 0.541\n",
      "x_train dims:  (14855, 1575)\n",
      "x_test dims :  (3957, 1575) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "data_path = \"/rds/general/project/hda_students_data/live/Group9/General/david/Data\"\n",
    "work_dir = '/rds/general/project/hda_students_data/live/Group9/General/david/'\n",
    "df10Colnames = pd.read_csv(os.path.join(work_dir, \"Data/hes_10yr_A00Z99_bin.csv\"), nrows=0).columns\n",
    "loadcols = df10Colnames[0:1].append(df10Colnames[5::]).append(df10Colnames[3:4]) #drops age,sex, triplet_id, casecont \n",
    "booleans = {name:'float32' for name in df10Colnames[5::]}\n",
    "df10 = pd.read_csv(os.path.join(work_dir, \"Data/hes_10yr_A00Z99_bin.csv\"),\n",
    "                                    usecols=loadcols, header=0, dtype=booleans)\n",
    "ukbcols = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"), nrows=0).columns\n",
    "loadcolsukb = ukbcols[1:-2] #drops melanoma incidence date and index\n",
    "dfuk = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"),\n",
    "                                    usecols=loadcolsukb, header=0)\n",
    "# merge hes with working dataset \n",
    "df_full = pd.merge(dfuk, df10, on='eid', how='left')\n",
    "print(len(df_full) == len(dfuk)) #make sure no extra rows added\n",
    "# remember to drop eid after merge\n",
    "df_full.drop(columns=['eid'], inplace=True)\n",
    "# drop columns which are objects and >= 80% missing values\n",
    "df_full = df_full.select_dtypes(exclude=['object'])          \n",
    "limitPer = len(df_full) * .40\n",
    "df_full = df_full.dropna(thresh=limitPer, axis=1)\n",
    "# train_test_split\n",
    "X = df_full\n",
    "Y = df_full[\"casecont\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 289)\n",
    "x_train = x_train.drop(labels = \"casecont\", axis = 1)\n",
    "x_test = x_test.drop(labels = \"casecont\", axis = 1)\n",
    "y_train.fillna(value=0, inplace=True)\n",
    "y_test.fillna(value=0, inplace=True)\n",
    "print(\"Initial test_train_split 0.25 and info about test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "# do mode imputation based on trainset, and transform test set\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x_train)\n",
    "x_train = imputer.transform(x_train)\n",
    "x_test = imputer.transform(x_test) # avoid data leakage\n",
    "# SMOTE instead of duplicating\n",
    "sm = SMOTE(sampling_strategy=0.85, random_state = 777)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "print(\"Performing SMOTE on test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "print(\"x_train dims: \", x_train.shape)\n",
    "print(\"x_test dims : \", x_test.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(x_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/rds/general/project/hda_students_data/live/Group9/General/Data/Final_final_final_datasets/UKb40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df.to_csv(\"X_train_10yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_train_df.to_csv(\"Y_train_10yr_UKb40_A00toZ99_bin.csv\")\n",
    "x_test_df.to_csv(\"X_test_10yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_test_df.to_csv(\"Y_test_10yr_UKb40_A00toZ99_bin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 year time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1142,1143,1145,1149,1150,1151,1230,1231,1232,1233,2928,2929,2939,2940,2944,2945,2946,2947,2948,2949,2950,2957,2958,2959,2960,2961,2962,2971,2972,2973,2974,2986,2987,2988,2989,2990,2991,2992,3014,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3195,3196,3199,3200,3201,3202,3203,3204,3205,3206,3207,3210,3212,3213) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Initial test_train_split 0.25 and info about test_set:\n",
      "Number and prop(%) of cases   :  3838 , % = 0.323\n",
      "Number and prop(%) of controls:  8030 , % = 0.677\n",
      "Performing SMOTE on test_set:\n",
      "Number and prop(%) of cases   :  6825 , % = 0.459\n",
      "Number and prop(%) of controls:  8030 , % = 0.541\n",
      "x_train dims:  (14855, 1461)\n",
      "x_test dims :  (3957, 1461) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "data_path = \"/rds/general/project/hda_students_data/live/Group9/General/david/Data\"\n",
    "work_dir = '/rds/general/project/hda_students_data/live/Group9/General/david/'\n",
    "df10Colnames = pd.read_csv(os.path.join(work_dir, \"../Data/1_3_5_10_hes/hes_5yr_A00Z99_bin.csv\"), nrows=0).columns\n",
    "loadcols = df10Colnames[0:1].append(df10Colnames[5::]).append(df10Colnames[3:4]) #drops age,sex, triplet_id, casecont \n",
    "booleans = {name:'float32' for name in df10Colnames[5::]}\n",
    "df10 = pd.read_csv(os.path.join(work_dir, \"../Data/1_3_5_10_hes/hes_5yr_A00Z99_bin.csv\"),\n",
    "                                    usecols=loadcols, header=0, dtype=booleans)\n",
    "ukbcols = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"), nrows=0).columns\n",
    "loadcolsukb = ukbcols[1:-2] #drops melanoma incidence date and index\n",
    "dfuk = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"),\n",
    "                                    usecols=loadcolsukb, header=0)\n",
    "# merge hes with working dataset \n",
    "df_full = pd.merge(dfuk, df10, on='eid', how='left')\n",
    "print(len(df_full) == len(dfuk)) #make sure no extra rows added\n",
    "# remember to drop eid after merge\n",
    "df_full.drop(columns=['eid'], inplace=True)\n",
    "# drop columns which are objects and >= 80% missing values\n",
    "df_full = df_full.select_dtypes(exclude=['object'])          \n",
    "limitPer = len(df_full) * .40\n",
    "df_full = df_full.dropna(thresh=limitPer, axis=1)\n",
    "# train_test_split\n",
    "X = df_full\n",
    "Y = df_full[\"casecont\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 289)\n",
    "x_train = x_train.drop(labels = \"casecont\", axis = 1)\n",
    "x_test = x_test.drop(labels = \"casecont\", axis = 1)\n",
    "y_train.fillna(value=0, inplace=True)\n",
    "y_test.fillna(value=0, inplace=True)\n",
    "print(\"Initial test_train_split 0.25 and info about test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "# do mode imputation based on trainset, and transform test set\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x_train)\n",
    "x_train = imputer.transform(x_train)\n",
    "x_test = imputer.transform(x_test) # avoid data leakage\n",
    "# SMOTE instead of duplicating\n",
    "sm = SMOTE(sampling_strategy=0.85, random_state = 777)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "print(\"Performing SMOTE on test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "print(\"x_train dims: \", x_train.shape)\n",
    "print(\"x_test dims : \", x_test.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(x_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/rds/general/project/hda_students_data/live/Group9/General/Data/Final_final_final_datasets/UKb40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df.to_csv(\"X_train_5yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_train_df.to_csv(\"Y_train_5yr_UKb40_A00toZ99_bin.csv\")\n",
    "x_test_df.to_csv(\"X_test_5yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_test_df.to_csv(\"Y_test_5yr_UKb40_A00toZ99_bin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 year time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1142,1143,1145,1149,1150,1151,1230,1231,1232,1233,2928,2929,2939,2940,2944,2945,2946,2947,2948,2949,2950,2957,2958,2959,2960,2961,2962,2971,2972,2973,2974,2986,2987,2988,2989,2990,2991,2992,3014,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3195,3196,3199,3200,3201,3202,3203,3204,3205,3206,3207,3210,3212,3213) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Initial test_train_split 0.25 and info about test_set:\n",
      "Number and prop(%) of cases   :  3838 , % = 0.323\n",
      "Number and prop(%) of controls:  8030 , % = 0.677\n",
      "Performing SMOTE on test_set:\n",
      "Number and prop(%) of cases   :  6825 , % = 0.459\n",
      "Number and prop(%) of controls:  8030 , % = 0.541\n",
      "x_train dims:  (14855, 1379)\n",
      "x_test dims :  (3957, 1379) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "data_path = \"/rds/general/project/hda_students_data/live/Group9/General/david/Data\"\n",
    "work_dir = '/rds/general/project/hda_students_data/live/Group9/General/david/'\n",
    "df10Colnames = pd.read_csv(os.path.join(work_dir, \"../Data/1_3_5_10_hes/hes_3yr_A00Z99_bin.csv\"), nrows=0).columns\n",
    "loadcols = df10Colnames[0:1].append(df10Colnames[5::]).append(df10Colnames[3:4]) #drops age,sex, triplet_id, casecont \n",
    "booleans = {name:'float32' for name in df10Colnames[5::]}\n",
    "df10 = pd.read_csv(os.path.join(work_dir, \"../Data/1_3_5_10_hes/hes_3yr_A00Z99_bin.csv\"),\n",
    "                                    usecols=loadcols, header=0, dtype=booleans)\n",
    "ukbcols = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"), nrows=0).columns\n",
    "loadcolsukb = ukbcols[1:-2] #drops melanoma incidence date and index\n",
    "dfuk = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"),\n",
    "                                    usecols=loadcolsukb, header=0)\n",
    "# merge hes with working dataset \n",
    "df_full = pd.merge(dfuk, df10, on='eid', how='left')\n",
    "print(len(df_full) == len(dfuk)) #make sure no extra rows added\n",
    "# remember to drop eid after merge\n",
    "df_full.drop(columns=['eid'], inplace=True)\n",
    "# drop columns which are objects and >= 80% missing values\n",
    "df_full = df_full.select_dtypes(exclude=['object'])          \n",
    "limitPer = len(df_full) * .40\n",
    "df_full = df_full.dropna(thresh=limitPer, axis=1)\n",
    "# train_test_split\n",
    "X = df_full\n",
    "Y = df_full[\"casecont\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 289)\n",
    "x_train = x_train.drop(labels = \"casecont\", axis = 1)\n",
    "x_test = x_test.drop(labels = \"casecont\", axis = 1)\n",
    "y_train.fillna(value=0, inplace=True)\n",
    "y_test.fillna(value=0, inplace=True)\n",
    "print(\"Initial test_train_split 0.25 and info about test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "# do mode imputation based on trainset, and transform test set\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x_train)\n",
    "x_train = imputer.transform(x_train)\n",
    "x_test = imputer.transform(x_test) # avoid data leakage\n",
    "# SMOTE instead of duplicating\n",
    "sm = SMOTE(sampling_strategy=0.85, random_state = 777)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "print(\"Performing SMOTE on test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "print(\"x_train dims: \", x_train.shape)\n",
    "print(\"x_test dims : \", x_test.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(x_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/rds/general/project/hda_students_data/live/Group9/General/Data/Final_final_final_datasets/UKb40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df.to_csv(\"X_train_3yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_train_df.to_csv(\"Y_train_3yr_UKb40_A00toZ99_bin.csv\")\n",
    "x_test_df.to_csv(\"X_test_3yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_test_df.to_csv(\"Y_test_3yr_UKb40_A00toZ99_bin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 year time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1142,1143,1145,1149,1150,1151,1230,1231,1232,1233,2928,2929,2939,2940,2944,2945,2946,2947,2948,2949,2950,2957,2958,2959,2960,2961,2962,2971,2972,2973,2974,2986,2987,2988,2989,2990,2991,2992,3014,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3195,3196,3199,3200,3201,3202,3203,3204,3205,3206,3207,3210,3212,3213) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Initial test_train_split 0.25 and info about test_set:\n",
      "Number and prop(%) of cases   :  3838 , % = 0.323\n",
      "Number and prop(%) of controls:  8030 , % = 0.677\n",
      "Performing SMOTE on test_set:\n",
      "Number and prop(%) of cases   :  6825 , % = 0.459\n",
      "Number and prop(%) of controls:  8030 , % = 0.541\n",
      "x_train dims:  (14855, 1143)\n",
      "x_test dims :  (3957, 1143) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "data_path = \"/rds/general/project/hda_students_data/live/Group9/General/david/Data\"\n",
    "work_dir = '/rds/general/project/hda_students_data/live/Group9/General/david/'\n",
    "df10Colnames = pd.read_csv(os.path.join(work_dir, \"../Data/1_3_5_10_hes/hes_1yr_A00Z99_bin.csv\"), nrows=0).columns\n",
    "loadcols = df10Colnames[0:1].append(df10Colnames[5::]).append(df10Colnames[3:4]) #drops age,sex, triplet_id, casecont \n",
    "booleans = {name:'float32' for name in df10Colnames[5::]}\n",
    "df10 = pd.read_csv(os.path.join(work_dir, \"../Data/1_3_5_10_hes/hes_1yr_A00Z99_bin.csv\"),\n",
    "                                    usecols=loadcols, header=0, dtype=booleans)\n",
    "ukbcols = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"), nrows=0).columns\n",
    "loadcolsukb = ukbcols[1:-2] #drops melanoma incidence date and index\n",
    "dfuk = pd.read_csv(os.path.join(work_dir, \"Data/working_dataset_notext.csv\"),\n",
    "                                    usecols=loadcolsukb, header=0)\n",
    "# merge hes with working dataset \n",
    "df_full = pd.merge(dfuk, df10, on='eid', how='left')\n",
    "print(len(df_full) == len(dfuk)) #make sure no extra rows added\n",
    "# remember to drop eid after merge\n",
    "df_full.drop(columns=['eid'], inplace=True)\n",
    "# drop columns which are objects and >= 80% missing values\n",
    "df_full = df_full.select_dtypes(exclude=['object'])          \n",
    "limitPer = len(df_full) * .40\n",
    "df_full = df_full.dropna(thresh=limitPer, axis=1)\n",
    "# train_test_split\n",
    "X = df_full\n",
    "Y = df_full[\"casecont\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 289)\n",
    "x_train = x_train.drop(labels = \"casecont\", axis = 1)\n",
    "x_test = x_test.drop(labels = \"casecont\", axis = 1)\n",
    "y_train.fillna(value=0, inplace=True)\n",
    "y_test.fillna(value=0, inplace=True)\n",
    "print(\"Initial test_train_split 0.25 and info about test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "# do mode imputation based on trainset, and transform test set\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x_train)\n",
    "x_train = imputer.transform(x_train)\n",
    "x_test = imputer.transform(x_test) # avoid data leakage\n",
    "# SMOTE instead of duplicating\n",
    "sm = SMOTE(sampling_strategy=0.85, random_state = 777)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "print(\"Performing SMOTE on test_set:\")\n",
    "print(\"Number and prop(%) of cases   : \", (y_train == 1).sum(), \n",
    "            \", % =\", round((y_train == 1).sum()/len(y_train), 3))\n",
    "print(\"Number and prop(%) of controls: \", (y_train == 0).sum(), \n",
    "            \", % =\", round((y_train == 0).sum()/len(y_train), 3))\n",
    "print(\"x_train dims: \", x_train.shape)\n",
    "print(\"x_test dims : \", x_test.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(x_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/rds/general/project/hda_students_data/live/Group9/General/Data/Final_final_final_datasets/UKb40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df.to_csv(\"X_train_1yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_train_df.to_csv(\"Y_train_1yr_UKb40_A00toZ99_bin.csv\")\n",
    "x_test_df.to_csv(\"X_test_1yr_UKb40_A00toZ99_bin.csv\")\n",
    "y_test_df.to_csv(\"Y_test_1yr_UKb40_A00toZ99_bin.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
